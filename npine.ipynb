{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import os\n",
    "import tqdm\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"C:\\\\Users\\\\abuza\\\\Desktop\\\\jobd - Copy\\\\JD-Prototype-1\\\\api.env\")\n",
    "\n",
    "\n",
    "pinecone.init(      \n",
    "\tapi_key='f0b91127-5366-4d48-a42e-6a79f45e80f6',      \n",
    "\tenvironment='asia-northeast1-gcp'      \n",
    ")       \n",
    "index = pinecone.Index('skills-database')\n",
    "\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science\\n\\n--Data Scientists Generalists:-\\nSkills:\\nGood with programming (Python or R)\\ndata manipulation (e.g., pandas)\\nbasic SQL, statistics, business acumen\\nbuilding basic Machine Learning algorithms and models\\nbasic data visualization (Tableau, etc.).\\n\\n--Data Scientists with Data Engineering Skills:-\\nSkills:\\nProficient with data management tools\\nETL processes, Data pipeline creation and optimization\\nbig data tools (e.g., Hadoop, Spark)\\nperhaps less knowledge of pure statistics and Machine Learning algorithms.\\n\\n--Data Scientists with Stakeholder Management Skills:-\\nSkills:\\nStrong business acumen\\ndomain knowledge\\nstakeholder relationship management\\nability to translate technical findings to nontechnical audiences\\npotentially less hands-on with Machine Learning modeling and coding\\n\\n--Data Scientists with Machine Learning Skills:-\\nSkills:\\nStrong in Machine Learning and coding\\nCan build and possibly deploy Machine Learning models\\nProficiency in Machine Learning frameworks (e.g., scikit-learn, TensorFlow)\\nModel evaluation and tuning, Model deployment\\nfamiliarity with a variety of algorithms (classification, regression, clustering).\\n\\n--Data Scientists with Statistics Skills:-\\nSkills:\\nEmphasis on statistics\\nA/B testing\\nhypothesis testing\\ncausal inference, etc. \\nPotentially less coding and Machine Learning modeling.\\n\\n--Data Scientist with Business Intelligence (BI) Skills:-\\nSkills:\\nFocused on reporting\\nBI tools (e.g., Tableau, PowerBI, QlikView)\\nStrong SQL Skills, business analysis\\nbusiness metrics and KPI understanding\\nDashboard design and deployment\\npotentially less statistics and Machine Learning molding.\\n\\n--Data Science with Quantitative Research Skills:-\\nSkills:\\nSpecializes in building quantitative models\\nalgorithmic trading strategies\\nrisk management\\nfinancial modeling and forecasting often for financial markets.\\n',\n",
       " \"Machine Learning\\n\\n--Machine Learning Engineer:-\\nSkills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques\\n\\n--Machine Learning Engineer with MlOps Skills:-\\nSkills:\\nSkilled in deploying Machine Learning models into production, infrastructure. Perhaps less involved in initial data manipulation or pure statistics.\\nKnowledge of deployment tools (e.g., Docker, Kubernetes)\\nContinuous integration and continuous deployment (CI/CD) practices\\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP)\\nScalability and performance optimization\\nMonitoring and maintaining Machine Learning models in production\\n\\n--Machine Learning Engineer with Research Skills:-\\nSkills:\\nDeep understanding of Machine Learning algorithms, strong in statistics, less focused on the practical deployment of Machine Learning models in a production environment or MLOps.\\nDeep understanding of advanced Machine Learning algorithms\\nFamiliarity with academic research and publications in the field\\nAdvanced statistics and mathematical Skills\\nExperience with deep learning frameworks (e.g., TensorFlow, PyTorch)\\nAbility to innovate and explore new methodologies\\n\\n--Machine Learning Engineers with Software Skills:-\\nSkills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing\\n\\n--Machine Learning Engineer with Data Science Skills:-\\nSkills:\\nBalanced Skills in statistics, data manipulation, prototyping, and potentially less involved in large-scale production deployments.\\nSolid grounding in statistics and data analysis\\nData preprocessing and transformation\\nMachine Learning: Proficiency in developing, training, and deploying machine learning models across diverse tasks.\\nStrong data manipulation, exploration, and visualization Skills, underpinned by a deep grasp of statistical concepts.\\nPython Programming: High-level coding Skills in Python, adept at both data analysis and machine learning applications.\\nData Preprocessing: Expertise in the intricate art of cleaning, transforming, and preparing data for model building.\\nFeature Engineering: The knack for crafting meaningful features from raw data, enhancing model performance.\\nModel Selection: Skillful selection of the most fitting machine learning algorithms for specific tasks, coupled with hyperparameter fine-tuning.\\nFamiliarity with deep neural networks, particularly for intricate tasks like image and text analysis.\\nData Analysis: Proficiency in conducting comprehensive exploratory data analysis (EDA) to reveal patterns and insights within datasets.\\nData Visualization: Expertise in crafting compelling data visualizations to eloquently convey findings.\\nMachine Learning Libraries: Seasoned experience with revered ML libraries and frameworks such as scikit-learn, TensorFlow, and PyTorch.\\nBig Data: Adept at managing and dissecting large datasets, often leveraging tools like Apache Spark.\\nDatabase Skills: Proficiency in working with databases and adept at querying data using SQL.\\nPredictive Modeling: Proficiency in developing models for tasks like classification, regression, clustering, and time series forecasting.\\nDeployment: The capability to proficiently deploy machine learning models into production systems.\\n\\n--Machine Learning Engineer with Deep Learning Skills:-\\nSkills:\\nProgramming: Python, C++\\nFocused on neural networks and deep learning models, potentially using frameworks like TensorFlow or PyTorch.\\nExpertise in deep learning architectures (e.g., CNN, RNN, Transformers)\\nProficiency with deep learning frameworks (e.g., TensorFlow, PyTorch, Keras, MXNet, Caffe)\\nGPU optimization and parallel processing\\nTransfer learning and fine-tuning models\\nAdvanced neural network tuning\\nTechniques & Models: Neural Networks, RNN, LSTM, GRU\\nknowledge of Transformer Architectures, Attention Mechanisms\\nAutoencoders, Variational Autoencoders\\n\\n--Machine Learning Engineer with NLP Skills:-\\nSkills:\\nText preprocessing (e.g., tokenization, POS tagging)\\nNLP Libraries & Frameworks: NLTK, SpaCy, Gensim, Transformer Libraries (Hugging Face)\\nUnderstanding of language models (e.g., BERT, GPT)\\nSentiment analysis, topic modeling, and entity recognition\\nTechniques & Models: Tokenization, Stemming, Lemmatization, Bag of Words, TF-IDF, Word2Vec, FastText, GloVe, Transformers: BERT, GPT, T5, etc.\\nSequence-to-Sequence Models\\nAttention Mechanisms\\nCloud Platforms: AWS (Comprehend, Translate), Google Cloud (Natural Language)\\n\\n--Machine Learning Engineer with Computer Vision Skills:-\\nSkills:\\nProgramming: Python, C++\\nComputer Vision Libraries & Frameworks: OpenCV, Pillow, ImageAI\\nTechniques & Models:\\nConvolutional Neural Networks (CNN)\\nTransfer Learning\\nImage Classification, Segmentation, Detection\\nGenerative Adversarial Networks (GAN)\\nObject Detection models: YOLO, SSD, Faster R-CNN\\nDatasets & Annotation Tools: COCO, ImageNet, Labelbox, VGG Image Annotato\\n\\n--Machine Learning Engineer with DevOps Skills:-\\nSkills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton\\n\\n--On-Device/Embedded Machine Learning Engineer:-\\nSkills:\\nProgramming: C, C++\\nEfficient low-level languages for constrained devices.\\nFrameworks & Tools: TensorFlow Lite, CoreML, ONNX, TinyML\\nFor building lightweight models suitable for mobile and embedded devices.\\n\\n--Machine Learning Engineer with Reinforcement Learning Skills:-\\nSkills:\\nPython Programming: Proficient in Python.\\nReinforcement Learning Algorithms: In-depth knowledge of Q-Learning, DQN, PPO, Actor-Critic, etc.\\nMathematics: Strong foundation in calculus, linear algebra, and probability.\\nReinforcement Learning Frameworks: Hands-on experience with OpenAI Gym, Stable Baselines, Reinforcement Learninglib.\\nReinforcement Learning Libraries: Familiar with OpenAI Baselines and Ray Reinforcement Learninglib.\\nReinforcement Learning Theory: Understand MDPs and Bellman equations.\\nOpenAI Tools: Familiarity with OpenAI's research and libraries.\\n\",\n",
       " 'Data Analyst\\n\\n--Data Visualization Experts:-\\nSkills:\\nProficiency in visualization libraries (e.g., D3.js, Matplotlib)\\nData storytelling and narrative creation\\nInteractive visualization design\\nIntegration of visualizations into web or applications\\nColor theory and design principles\\n\\n--Data Analysts:-\\nSkills:\\nStrong SQL querying Skills\\nData cleaning and munging\\nBasic statistical analysis\\nReporting and insights derivation\\nExperience with analytics platforms (e.g., Google Analytics)\\n\\n--Cybersecurity Data Analysts:-\\nSkills:\\nIntrusion detection systems and their logs\\nNetwork traffic analysis\\nMalware detection and analysis\\nBehavioral analytics for cybersecurity\\nThreat intelligence and landscape analysis\\n',\n",
       " 'AI Experts\\n\\n--AI Ethics and Fairness Experts:-\\nSkills:\\nUnderstanding of biases in AI and mitigation techniques\\nEthical considerations in model deployment\\nTransparency and interpretability methods\\nRegulatory and compliance knowledge related to AI\\nStakeholder communication on ethical concerns\\n\\n--Chatbot and Conversational AI Developers:-\\nSkills:\\nDialogue system architectures\\nIntent recognition and slot filling\\nConversational flow design\\nIntegration with messaging platforms (e.g., Messenger, Slack)\\nVoice recognition and processing\\n\\n--Edge AI Specialists:-\\nSkills:\\nModel quantization and optimization for edge devices\\nEdge computing platforms (e.g., AWS Greengrass)\\nReal-time data processing at the edge\\nEnergy-efficient Machine Learning\\nOn-device learning techniques\\n',\n",
       " 'Roboticist\\n\\n--Robotics Expert Generalist:-\\nSkills:\\nProgramming: Python, C++, ROS (Robot Operating System)\\nRobotics Frameworks & Libraries: ROS, Gazebo\\nTechniques & Tools:\\nSLAM (Simultaneous Localization and Mapping)\\nPath Planning Algorithms\\nSensor Fusion\\nPID Control\\nReinforcement Learning for Robotics\\nRobotics Hardware Knowledge: Actuators, Sensors, Embedded Systems\\n\\n--Robotic Process Automation (RPA) Experts:-\\nSkills:\\nFamiliarity with RPA tools (e.g., UiPath, Blue Prism)\\nProcess mapping and optimization\\nIntegration of AI/Machine Learning into automated processes\\nBot lifecycle management\\nDebugging and error handling in automation scenarios']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_and_separate_roles(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    # Split the data into individual roles based on two newline characters\n",
    "    role = data.split('\\n---')    \n",
    "    return role\n",
    "\n",
    "def make_embeddings(string):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    result = embeddings.embed_documents(texts=string)\n",
    "    return result[0]\n",
    "\n",
    "# Provide the file path to your text file\n",
    "file_path = 'real.txt'\n",
    "\n",
    "# Read and separate the roles\n",
    "roles = read_and_separate_roles(file_path)\n",
    "roles\n",
    "# roles[2].split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 27):\n",
    "    index.delete(ids= [str(i)], namespace='Roboticist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subrole:Skills:\n",
      "Good with programming (Python or R)\n",
      "data manipulation (e.g., pandas)\n",
      "basic SQL, statistics, business acumen\n",
      "building basic Machine Learning algorithms and models\n",
      "basic data visualization (Tableau, etc.).\n",
      "subrole:Skills:\n",
      "Proficient with data management tools\n",
      "ETL processes, Data pipeline creation and optimization\n",
      "big data tools (e.g., Hadoop, Spark)\n",
      "perhaps less knowledge of pure statistics and Machine Learning algorithms.\n",
      "subrole:Skills:\n",
      "Strong business acumen\n",
      "domain knowledge\n",
      "stakeholder relationship management\n",
      "ability to translate technical findings to nontechnical audiences\n",
      "potentially less hands-on with Machine Learning modeling and coding\n",
      "subrole:Skills:\n",
      "Strong in Machine Learning and coding\n",
      "Can build and possibly deploy Machine Learning models\n",
      "Proficiency in Machine Learning frameworks (e.g., scikit-learn, TensorFlow)\n",
      "Model evaluation and tuning, Model deployment\n",
      "familiarity with a variety of algorithms (classification, regression, clustering).\n",
      "subrole:Skills:\n",
      "Emphasis on statistics\n",
      "A/B testing\n",
      "hypothesis testing\n",
      "causal inference, etc. \n",
      "Potentially less coding and Machine Learning modeling.\n",
      "subrole:Skills:\n",
      "Focused on reporting\n",
      "BI tools (e.g., Tableau, PowerBI, QlikView)\n",
      "Strong SQL Skills, business analysis\n",
      "business metrics and KPI understanding\n",
      "Dashboard design and deployment\n",
      "potentially less statistics and Machine Learning molding.\n",
      "subrole:Skills:\n",
      "Specializes in building quantitative models\n",
      "algorithmic trading strategies\n",
      "risk management\n",
      "financial modeling and forecasting often for financial markets.\n",
      "subrole:Skills:\n",
      "Tools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\n",
      "Coding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\n",
      "Data Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\n",
      "Model Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques\n",
      "subrole:Skills:\n",
      "Skilled in deploying Machine Learning models into production, infrastructure. Perhaps less involved in initial data manipulation or pure statistics.\n",
      "Knowledge of deployment tools (e.g., Docker, Kubernetes)\n",
      "Continuous integration and continuous deployment (CI/CD) practices\n",
      "Familiarity with cloud platforms (e.g., AWS, Azure, GCP)\n",
      "Scalability and performance optimization\n",
      "Monitoring and maintaining Machine Learning models in production\n",
      "subrole:Skills:\n",
      "Deep understanding of Machine Learning algorithms, strong in statistics, less focused on the practical deployment of Machine Learning models in a production environment or MLOps.\n",
      "Deep understanding of advanced Machine Learning algorithms\n",
      "Familiarity with academic research and publications in the field\n",
      "Advanced statistics and mathematical Skills\n",
      "Experience with deep learning frameworks (e.g., TensorFlow, PyTorch)\n",
      "Ability to innovate and explore new methodologies\n",
      "subrole:Skills:\n",
      "Excellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\n",
      "Proficiency in multiple programming languages (e.g., Java, C++, Python)\n",
      "Software development best practices (e.g., version control, testing)\n",
      "Integration of Machine Learning libraries and APIs\n",
      "System design and architecture understanding\n",
      "Familiarity with distributed computing\n",
      "subrole:Skills:\n",
      "Balanced Skills in statistics, data manipulation, prototyping, and potentially less involved in large-scale production deployments.\n",
      "Solid grounding in statistics and data analysis\n",
      "Data preprocessing and transformation\n",
      "Machine Learning: Proficiency in developing, training, and deploying machine learning models across diverse tasks.\n",
      "Strong data manipulation, exploration, and visualization Skills, underpinned by a deep grasp of statistical concepts.\n",
      "Python Programming: High-level coding Skills in Python, adept at both data analysis and machine learning applications.\n",
      "Data Preprocessing: Expertise in the intricate art of cleaning, transforming, and preparing data for model building.\n",
      "Feature Engineering: The knack for crafting meaningful features from raw data, enhancing model performance.\n",
      "Model Selection: Skillful selection of the most fitting machine learning algorithms for specific tasks, coupled with hyperparameter fine-tuning.\n",
      "Familiarity with deep neural networks, particularly for intricate tasks like image and text analysis.\n",
      "Data Analysis: Proficiency in conducting comprehensive exploratory data analysis (EDA) to reveal patterns and insights within datasets.\n",
      "Data Visualization: Expertise in crafting compelling data visualizations to eloquently convey findings.\n",
      "Machine Learning Libraries: Seasoned experience with revered ML libraries and frameworks such as scikit-learn, TensorFlow, and PyTorch.\n",
      "Big Data: Adept at managing and dissecting large datasets, often leveraging tools like Apache Spark.\n",
      "Database Skills: Proficiency in working with databases and adept at querying data using SQL.\n",
      "Predictive Modeling: Proficiency in developing models for tasks like classification, regression, clustering, and time series forecasting.\n",
      "Deployment: The capability to proficiently deploy machine learning models into production systems.\n",
      "subrole:Skills:\n",
      "Programming: Python, C++\n",
      "Focused on neural networks and deep learning models, potentially using frameworks like TensorFlow or PyTorch.\n",
      "Expertise in deep learning architectures (e.g., CNN, RNN, Transformers)\n",
      "Proficiency with deep learning frameworks (e.g., TensorFlow, PyTorch, Keras, MXNet, Caffe)\n",
      "GPU optimization and parallel processing\n",
      "Transfer learning and fine-tuning models\n",
      "Advanced neural network tuning\n",
      "Techniques & Models: Neural Networks, RNN, LSTM, GRU\n",
      "knowledge of Transformer Architectures, Attention Mechanisms\n",
      "Autoencoders, Variational Autoencoders\n",
      "subrole:Skills:\n",
      "Text preprocessing (e.g., tokenization, POS tagging)\n",
      "NLP Libraries & Frameworks: NLTK, SpaCy, Gensim, Transformer Libraries (Hugging Face)\n",
      "Understanding of language models (e.g., BERT, GPT)\n",
      "Sentiment analysis, topic modeling, and entity recognition\n",
      "Techniques & Models: Tokenization, Stemming, Lemmatization, Bag of Words, TF-IDF, Word2Vec, FastText, GloVe, Transformers: BERT, GPT, T5, etc.\n",
      "Sequence-to-Sequence Models\n",
      "Attention Mechanisms\n",
      "Cloud Platforms: AWS (Comprehend, Translate), Google Cloud (Natural Language)\n",
      "subrole:Skills:\n",
      "Programming: Python, C++\n",
      "Computer Vision Libraries & Frameworks: OpenCV, Pillow, ImageAI\n",
      "Techniques & Models:\n",
      "Convolutional Neural Networks (CNN)\n",
      "Transfer Learning\n",
      "Image Classification, Segmentation, Detection\n",
      "Generative Adversarial Networks (GAN)\n",
      "Object Detection models: YOLO, SSD, Faster R-CNN\n",
      "Datasets & Annotation Tools: COCO, ImageNet, Labelbox, VGG Image Annotato\n",
      "subrole:Skills:\n",
      "Programming: Python, YAML (for CI/CD configuration)\n",
      "Techniques & Tools:\n",
      "Continuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\n",
      "Model Monitoring: Prometheus, Grafana\n",
      "Model Versioning: DVC, MLflow\n",
      "Experiment Tracking: WandB, TensorBoard\n",
      "Deployment: Docker, Kubernetes, Seldon, TFX\n",
      "Feature Stores: Feast, Tecton\n",
      "subrole:Skills:\n",
      "Programming: C, C++\n",
      "Efficient low-level languages for constrained devices.\n",
      "Frameworks & Tools: TensorFlow Lite, CoreML, ONNX, TinyML\n",
      "For building lightweight models suitable for mobile and embedded devices.\n",
      "subrole:Skills:\n",
      "Python Programming: Proficient in Python.\n",
      "Reinforcement Learning Algorithms: In-depth knowledge of Q-Learning, DQN, PPO, Actor-Critic, etc.\n",
      "Mathematics: Strong foundation in calculus, linear algebra, and probability.\n",
      "Reinforcement Learning Frameworks: Hands-on experience with OpenAI Gym, Stable Baselines, Reinforcement Learninglib.\n",
      "Reinforcement Learning Libraries: Familiar with OpenAI Baselines and Ray Reinforcement Learninglib.\n",
      "Reinforcement Learning Theory: Understand MDPs and Bellman equations.\n",
      "OpenAI Tools: Familiarity with OpenAI's research and libraries.\n",
      "subrole:Skills:\n",
      "Proficiency in visualization libraries (e.g., D3.js, Matplotlib)\n",
      "Data storytelling and narrative creation\n",
      "Interactive visualization design\n",
      "Integration of visualizations into web or applications\n",
      "Color theory and design principles\n",
      "subrole:Skills:\n",
      "Strong SQL querying Skills\n",
      "Data cleaning and munging\n",
      "Basic statistical analysis\n",
      "Reporting and insights derivation\n",
      "Experience with analytics platforms (e.g., Google Analytics)\n",
      "subrole:Skills:\n",
      "Intrusion detection systems and their logs\n",
      "Network traffic analysis\n",
      "Malware detection and analysis\n",
      "Behavioral analytics for cybersecurity\n",
      "Threat intelligence and landscape analysis\n",
      "subrole:Skills:\n",
      "Understanding of biases in AI and mitigation techniques\n",
      "Ethical considerations in model deployment\n",
      "Transparency and interpretability methods\n",
      "Regulatory and compliance knowledge related to AI\n",
      "Stakeholder communication on ethical concerns\n",
      "subrole:Skills:\n",
      "Dialogue system architectures\n",
      "Intent recognition and slot filling\n",
      "Conversational flow design\n",
      "Integration with messaging platforms (e.g., Messenger, Slack)\n",
      "Voice recognition and processing\n",
      "subrole:Skills:\n",
      "Model quantization and optimization for edge devices\n",
      "Edge computing platforms (e.g., AWS Greengrass)\n",
      "Real-time data processing at the edge\n",
      "Energy-efficient Machine Learning\n",
      "On-device learning techniques\n",
      "subrole:Skills:\n",
      "Programming: Python, C++, ROS (Robot Operating System)\n",
      "Robotics Frameworks & Libraries: ROS, Gazebo\n",
      "Techniques & Tools:\n",
      "SLAM (Simultaneous Localization and Mapping)\n",
      "Path Planning Algorithms\n",
      "Sensor Fusion\n",
      "PID Control\n",
      "Reinforcement Learning for Robotics\n",
      "Robotics Hardware Knowledge: Actuators, Sensors, Embedded Systems\n",
      "subrole:Skills:\n",
      "Familiarity with RPA tools (e.g., UiPath, Blue Prism)\n",
      "Process mapping and optimization\n",
      "Integration of AI/Machine Learning into automated processes\n",
      "Bot lifecycle management\n",
      "Debugging and error handling in automation scenarios\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "i = 0\n",
    "for role in roles:\n",
    "    namespace = role.split(\"\\n\\n--\")[0]\n",
    "    n = role.split('--')[1:]\n",
    "    for subrole in n:\n",
    "        role_title = subrole.split(':')[0]\n",
    "        description = subrole.split(':-\\n')[1].strip()\n",
    "        print(f'subrole:{description}')\n",
    "        i = i+1\n",
    "        response = openai.Embedding.create(\n",
    "        input=description,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        embeddings = response['data'][0]['embedding']\n",
    "        index.upsert([\n",
    "        (f'{i}', embeddings, {'role title': role_title, 'description': description})\n",
    "        ],namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is testing portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skills:\\n- Python\\n- Java\\n- AWS cloud\\n- SageMaker\\n- EMR\\n- S3\\n- VPC endpoint\\n- CI/CD pipelines\\n- Jenkins\\n- Spinnaker\\n- Bitbucket\\n- Splunk\\n- CloudWatch\\n- Grafana\\n- Dynatrace\\n- Terraform\\n- Kubernetes\\n- machine learning frameworks (Keras or PyTorch)\\n- scikit-learn\\n- data pipelines\\n- HADOOP\\n- Hive\\n- Redshift\\n- AWS certification (Developer or Architect or Client Specialty)\\n- distributed systems\\n- cloud computing environments\\n- Programming skills in Python, Bash, Groovy\\n- REST\\n- Internet and Web Technologies\\n- network protocols (DNS, HTTP)\\n- network security\\n- industry-wide technology trends and best practices\\n- ability to work in large, collaborative teams'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description = \"\"\"Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\"\"\"\n",
    "job_description.strip()\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "llm_response = llm.predict(f\"\"\"\n",
    "Role : You are a human resources agent who specializes in cantidates in the Artificial Intellegence, Machine Learning, and Data Engineering space.\n",
    "Task: Extract the technical skills from the provided Job Description, ordering them from most fundamental to most niche\n",
    "Job Description:\n",
    "<<{job_description.strip()}>>\n",
    "Output Format:\n",
    "Skills:\n",
    "-\n",
    "-\n",
    "\"\"\")\n",
    "llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Embedding.create(\n",
    "    input=llm_response,\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "query_embeddings = response['data'][0]['embedding']\n",
    "len(query_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '11',\n",
       "              'metadata': {'description': 'Skills:\\n'\n",
       "                                          'Excellent coding abilities in '\n",
       "                                          'languages like Java, C++, Scala, '\n",
       "                                          'Pyspark, and/or Python. Relies more '\n",
       "                                          'on existing Machine Learning '\n",
       "                                          'libraries, and less depth in '\n",
       "                                          'statistics and building Machine '\n",
       "                                          'Learning models from scratch.\\n'\n",
       "                                          'Proficiency in multiple programming '\n",
       "                                          'languages (e.g., Java, C++, '\n",
       "                                          'Python)\\n'\n",
       "                                          'Software development best practices '\n",
       "                                          '(e.g., version control, testing)\\n'\n",
       "                                          'Integration of Machine Learning '\n",
       "                                          'libraries and APIs\\n'\n",
       "                                          'System design and architecture '\n",
       "                                          'understanding\\n'\n",
       "                                          'Familiarity with distributed '\n",
       "                                          'computing',\n",
       "                           'role title': 'Machine Learning Engineers with '\n",
       "                                         'Software Skills'},\n",
       "              'score': 0.903367,\n",
       "              'values': []},\n",
       "             {'id': '16',\n",
       "              'metadata': {'description': 'Skills:\\n'\n",
       "                                          'Programming: Python, YAML (for '\n",
       "                                          'CI/CD configuration)\\n'\n",
       "                                          'Techniques & Tools:\\n'\n",
       "                                          'Continuous Integration and '\n",
       "                                          'Continuous Deployment (CI/CD) for '\n",
       "                                          'Machine Learning: Jenkins, GitLab '\n",
       "                                          'CI, GitHub Actions\\n'\n",
       "                                          'Model Monitoring: Prometheus, '\n",
       "                                          'Grafana\\n'\n",
       "                                          'Model Versioning: DVC, MLflow\\n'\n",
       "                                          'Experiment Tracking: WandB, '\n",
       "                                          'TensorBoard\\n'\n",
       "                                          'Deployment: Docker, Kubernetes, '\n",
       "                                          'Seldon, TFX\\n'\n",
       "                                          'Feature Stores: Feast, Tecton',\n",
       "                           'role title': 'Machine Learning Engineer with '\n",
       "                                         'DevOps Skills'},\n",
       "              'score': 0.891522288,\n",
       "              'values': []},\n",
       "             {'id': '8',\n",
       "              'metadata': {'description': 'Skills:\\n'\n",
       "                                          'Tools and softwares: Familiarity '\n",
       "                                          'with a variety of machine learning '\n",
       "                                          'algorithms, from supervised '\n",
       "                                          'learning (e.g., regression, '\n",
       "                                          'classification) to unsupervised '\n",
       "                                          'learning (e.g., clustering, '\n",
       "                                          'dimensionality reduction).\\n'\n",
       "                                          'Coding Proficiency: Strong '\n",
       "                                          'programming Skills, typically in '\n",
       "                                          'Python or another Machine '\n",
       "                                          'Learning-relevant language (C++, '\n",
       "                                          'Java, etc.), and familiarity with '\n",
       "                                          'multiple Machine Learning libraries '\n",
       "                                          'and frameworks like scikit-learn, '\n",
       "                                          'TensorFlow, and PyTorch.\\n'\n",
       "                                          'Data Handling: Skills in data '\n",
       "                                          'preprocessing, cleaning, and '\n",
       "                                          'transformation. Comfortable with '\n",
       "                                          'tools for data manipulation like '\n",
       "                                          'Pandas, and databases or data '\n",
       "                                          'storage systems like SQL, NoSQL, '\n",
       "                                          'Hadoop, or Spark. Some knowledge of '\n",
       "                                          'cloud Platforms: AWS, Microsoft '\n",
       "                                          'Azure, and Google Cloud.\\n'\n",
       "                                          'Model Deployment & Monitoring: '\n",
       "                                          'model deployment, monitoring '\n",
       "                                          'performance, Model Evaluation, '\n",
       "                                          'Model Optimization, Hyperparameter '\n",
       "                                          'Tuning, Regularization, and Model '\n",
       "                                          'Training Techniques',\n",
       "                           'role title': 'Machine Learning Engineer'},\n",
       "              'score': 0.891344428,\n",
       "              'values': []}],\n",
       " 'namespace': 'Machine Learning'}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_format = index.query(\n",
    "query_embeddings,\n",
    "include_metadata=True,\n",
    "top_k=3,\n",
    "namespace='Machine Learning'\n",
    ")\n",
    "\n",
    "json_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills:\n",
      "Excellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\n",
      "Proficiency in multiple programming languages (e.g., Java, C++, Python)\n",
      "Software development best practices (e.g., version control, testing)\n",
      "Integration of Machine Learning libraries and APIs\n",
      "System design and architecture understanding\n",
      "Familiarity with distributed computing\n",
      "Skills:\n",
      "Programming: Python, YAML (for CI/CD configuration)\n",
      "Techniques & Tools:\n",
      "Continuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\n",
      "Model Monitoring: Prometheus, Grafana\n",
      "Model Versioning: DVC, MLflow\n",
      "Experiment Tracking: WandB, TensorBoard\n",
      "Deployment: Docker, Kubernetes, Seldon, TFX\n",
      "Feature Stores: Feast, Tecton\n",
      "Skills:\n",
      "Tools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\n",
      "Coding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\n",
      "Data Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\n",
      "Model Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques\n",
      "['Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing', 'Skills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton', 'Skills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques']\n"
     ]
    }
   ],
   "source": [
    "response_list =[]\n",
    "for i in range(3):\n",
    "    response = json_format['matches'][i]['metadata']['description']\n",
    "    print(response)\n",
    "    context = response_list.append(response)\n",
    "\n",
    "resposne_string = '\\n'.join(response_list)\n",
    "\n",
    "print(response_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATBOT Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'assistant', 'content': \"\\n                Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\\n                Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\\n                -Go step by step in a friendly and INTERACTIVE way. \\n                -Only one question in 1 term. The question should be from the perspective of the hiring manager3\\n                -Do  not give a sense that we have made a skill set\\n                Seniority Level: Manager-Hands On\\n\\n                Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n                Standard Skillset and Title: Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing\\nSkills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton\\nSkills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques\\n\\n                Output format: Question...?\\n                ###\\n                \"}, {'role': 'assistant', 'content': 'Question 1: Does the candidate need to have experience in developing and productionizing Python and Java applications?'}, {'role': 'user', 'content': 'yes they shou;d have '}]\n",
      "[{'role': 'assistant', 'content': \"\\n                Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\\n                Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\\n                -Go step by step in a friendly and INTERACTIVE way. \\n                -Only one question in 1 term. The question should be from the perspective of the hiring manager3\\n                -Do  not give a sense that we have made a skill set\\n                Seniority Level: Manager-Hands On\\n\\n                Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n                Standard Skillset and Title: Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing\\nSkills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton\\nSkills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques\\n\\n                Output format: Question...?\\n                ###\\n                \"}, {'role': 'assistant', 'content': 'Question 1: Does the candidate need to have experience in developing and productionizing Python and Java applications?'}, {'role': 'user', 'content': 'yes they shou;d have '}, {'role': 'assistant', 'content': 'Question 2: Is it necessary for the candidate to have hands-on experience in deploying Client applications to AWS cloud using SageMaker, EMR, S3, VPC endpoint, etc.?'}, {'role': 'user', 'content': 'yes '}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range (1,4):\n",
    "        if i ==1:\n",
    "                messages=[{\"role\": \"human\", \"content\": f'''\n",
    "                Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\n",
    "                Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\n",
    "                -Go step by step in a friendly and INTERACTIVE way. \n",
    "                -Only one question in 1 term. The question should be from the perspective of the hiring manager3\n",
    "                -Do  not give a sense that we have made a skill set\n",
    "                Seniority Level: Manager-Hands On\n",
    "\n",
    "                Job Description: {job_description}\n",
    "\n",
    "                Standard Skillset and Title: {resposne_string}\n",
    "\n",
    "                Output format: Question...?\n",
    "                ###\n",
    "                '''}]\n",
    "        question = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages = messages,\n",
    "                        temperature = 0.0)\n",
    "        question = question['choices'][0]['message']['content']\n",
    "        \n",
    "        human_input = input(f'Enter answer to {question}')\n",
    "        if human_input:\n",
    "                messages.append({\"role\":\"assistant\",\"content\":question})\n",
    "                messages.append({\"role\":\"user\", \"content\": human_input})\n",
    "                print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages = messages,\n",
    "                temperature = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8EFBrgQJbN2rMWH1nbcAVhh1TTqO3 at 0x1c5edbbcad0> JSON: {\n",
       "  \"id\": \"chatcmpl-8EFBrgQJbN2rMWH1nbcAVhh1TTqO3\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1698405675,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Based on the Job Description and the Seniority Level of the job, it is important to include all the requisite technical skills in the job description. This ensures that candidates who possess the necessary skills are attracted to the job and apply accordingly. \\n\\nNow, let's go through the Job Description and compare it with the Standard Skillset and Suggested Title to determine if all the required technical skills are included. \\n\\nFirst, let's start with the programming languages. Does the Job Description mention any programming languages that are required for this role?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 1047,\n",
       "    \"completion_tokens\": 106,\n",
       "    \"total_tokens\": 1153\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "      Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\n",
      "      Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\n",
      "      -Go step by step in a friendly and INTERACTIVE way. \n",
      "      -Only one question in 1 term. The question should be from the perspective of the hiring manager3\n",
      "      -Do  not give a sense that we have made a skill set\n",
      "      Seniority Level: Manager-Hands On\n",
      "\n",
      "      Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\n",
      "\n",
      "      Standard Skillset and Title: ['Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing', 'Skills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton', 'Skills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques']\n",
      "\n",
      "      Output format: Question...?\n",
      "      ###\n",
      "      \n",
      "AI: From the job description you've provided, it seems you're looking for a candidate with substantial machine learning experience, and familiarity with various coding languages, AWS applications, and CI/CD pipelines. I noticed the requirement for 'Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)'. Just to confirm, are you also expecting the candidate to have proficiency in multiple programming languages such as Java, C++, Python as well as software development best practices as part of their skill set?\n",
      "Human: No it us not needed\n",
      "AI: Understood. Considering the seniority level of the role, your candidate would need strong expertise in deploying client applications to the AWS cloud as you've mentioned. However, are you also considering familiarity with distributed computing as an important requisite for this position?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: \n",
      "      Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\n",
      "      Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\n",
      "      -Go step by step in a friendly and INTERACTIVE way. \n",
      "      -Only one question in 1 term. The question should be from the perspective of the hiring manager3\n",
      "      -Do  not give a sense that we have made a skill set\n",
      "      Seniority Level: Manager-Hands On\n",
      "\n",
      "      Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\n",
      "\n",
      "      Standard Skillset and Title: ['Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing', 'Skills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton', 'Skills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques']\n",
      "\n",
      "      Output format: Question...?\n",
      "      ###\n",
      "      \n",
      "AI: Based on the job description, I see that the candidate is required to have experience with Python and Java applications, AWS applications, CI/CD pipelines and tools, machine learning frameworks, and data pipelines. However, I don't see any mention of experience with languages like C++ and Scala. Would it be beneficial to include proficiency in these languages as part of the job requirements?\n",
      "Human: yes candidates needs to have an experience with scala\n",
      "AI: Great, thank you for confirming that. In addition to Scala, the standard skill set also suggests proficiency in Pyspark. Would you like to include this in your job requirements as well?\n",
      "Human: No it us not needed\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Understood. The standard skill set also indicates a need for knowledge in system design and architecture. Does the role require this expertise as well?'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'No it us not needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: \n",
      "      Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\n",
      "      Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\n",
      "      -Go step by step in a friendly and INTERACTIVE way. \n",
      "      -Only one question in 1 term. The question should be from the perspective of the hiring manager3\n",
      "      -Do  not give a sense that we have made a skill set\n",
      "      Seniority Level: Manager-Hands On\n",
      "\n",
      "      Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\n",
      "\n",
      "      Standard Skillset and Title: ['Skills:\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\nSoftware development best practices (e.g., version control, testing)\\nIntegration of Machine Learning libraries and APIs\\nSystem design and architecture understanding\\nFamiliarity with distributed computing', 'Skills:\\nProgramming: Python, YAML (for CI/CD configuration)\\nTechniques & Tools:\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\nModel Monitoring: Prometheus, Grafana\\nModel Versioning: DVC, MLflow\\nExperiment Tracking: WandB, TensorBoard\\nDeployment: Docker, Kubernetes, Seldon, TFX\\nFeature Stores: Feast, Tecton', 'Skills:\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques']\n",
      "\n",
      "      Output format: Question...?\n",
      "      ###\n",
      "      \n",
      "AI: Based on the job description, I see that the candidate is required to have experience with Python and Java applications, AWS applications, CI/CD pipelines and tools, machine learning frameworks, and data pipelines. However, I don't see any mention of experience with languages like C++ and Scala. Would it be beneficial to include proficiency in these languages as part of the job requirements?\n",
      "Human: yes candidates needs to have an experience with scala\n",
      "AI: Great, thank you for confirming that. In addition to Scala, the standard skill set also suggests proficiency in Pyspark. Would you like to include this in your job requirements as well?\n",
      "Human: No it us not needed\n",
      "AI: Understood. The standard skill set also indicates a need for knowledge in system design and architecture. Does the role require this expertise as well?\n",
      "Human: yes needed\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you for confirming. Another skill mentioned in the standard skill set is familiarity with distributed computing. Should this be included in the job description as well?'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input= 'yes needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: \\n      Role: You are an expert recruitment marketing specialist that is reviewing a Job Description submitted by a hiring manager. You have to question the user for details\\n      Task: You are trying to determine, based on a hiring manager's Job Description and the Job's Seniority Level, if they have included all the requisite technical skills in their job description that a candidate should posses to apply for the Job. Given the Job's Seniority level, you will compare the hiring manager's Job Description, with Standard Skillset and Suggested Title.\\n      -Go step by step in a friendly and INTERACTIVE way. \\n      -Only one question in 1 term. The question should be from the perspective of the hiring manager3\\n      -Do  not give a sense that we have made a skill set\\n      Seniority Level: Manager-Hands On\\n\\n      Job Description: Rate:  upto $135k - $140k/ 80/hr MA Title:  AI/ Client Engineer Location:  Columbus, OH/ Wilmington, DE (Day 1 Onsite)Job Description Proven experience as a Machine Learning Engineer or similar role  Expert level experience in Client SDLC, developing and productionizing Python and Java applications  Expert level hands on experience in deploying Client applications to AWS cloud using (SageMaker, EMR, S3, VPC endpoint etc.)  Hands on experience in AWS apps such EMR, Sage Maker , Cloud Watch, S3 Data Lake etc. ((this is a must)  Strong knowledge in CI/CD pipelines and tools such as Jenkins, Spinnaker, Bitbucket, Splunk, CloudWatch, Grafana, Dynatrace, Terraform .. etc. (this is a must)  Experience in deploying applications Kubernetes and AWS platform.  Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)  Familiarity with data pipelines, HADOOP, Hive, Redshift etc.  AWS certification (Developer or Architect or Client Specialty) is a huge plus.  Experience deploying and scaling distributed systems in a cloud environment (preferably AWS implementations)  Advanced knowledge of architecture and design across all systems and cloud computing environments  Strong Programming skills in Python, Bash, Groovy and software engineering principles.  Develop high quality, secure, scalable software solutions based on technical requirements specifications and design artifacts within expected time and budget.  Research, create and evaluate technical solution alternatives for the business needs.  Experienced in building REST.  Extensive experience of Internet and Web Technologies including a strong understanding of network protocols such as DNS, HTTP, and associated tools and technologies  Strong understanding of network protocols and network security  Passionate about building an innovative and team centric culture.  Knowledge of industry-wide technology trends and best practices  Ability to work in large, collaborative teams to achieve organizational goals.  Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\\n\\n      Standard Skillset and Title: ['Skills:\\\\nExcellent coding abilities in languages like Java, C++, Scala, Pyspark, and/or Python. Relies more on existing Machine Learning libraries, and less depth in statistics and building Machine Learning models from scratch.\\\\nProficiency in multiple programming languages (e.g., Java, C++, Python)\\\\nSoftware development best practices (e.g., version control, testing)\\\\nIntegration of Machine Learning libraries and APIs\\\\nSystem design and architecture understanding\\\\nFamiliarity with distributed computing', 'Skills:\\\\nProgramming: Python, YAML (for CI/CD configuration)\\\\nTechniques & Tools:\\\\nContinuous Integration and Continuous Deployment (CI/CD) for Machine Learning: Jenkins, GitLab CI, GitHub Actions\\\\nModel Monitoring: Prometheus, Grafana\\\\nModel Versioning: DVC, MLflow\\\\nExperiment Tracking: WandB, TensorBoard\\\\nDeployment: Docker, Kubernetes, Seldon, TFX\\\\nFeature Stores: Feast, Tecton', 'Skills:\\\\nTools and softwares: Familiarity with a variety of machine learning algorithms, from supervised learning (e.g., regression, classification) to unsupervised learning (e.g., clustering, dimensionality reduction).\\\\nCoding Proficiency: Strong programming Skills, typically in Python or another Machine Learning-relevant language (C++, Java, etc.), and familiarity with multiple Machine Learning libraries and frameworks like scikit-learn, TensorFlow, and PyTorch.\\\\nData Handling: Skills in data preprocessing, cleaning, and transformation. Comfortable with tools for data manipulation like Pandas, and databases or data storage systems like SQL, NoSQL, Hadoop, or Spark. Some knowledge of cloud Platforms: AWS, Microsoft Azure, and Google Cloud.\\\\nModel Deployment & Monitoring: model deployment, monitoring performance, Model Evaluation, Model Optimization, Hyperparameter Tuning, Regularization, and Model Training Techniques']\\n\\n      Output format: Question...?\\n      ###\\n      \\nAI: Based on the job description, I see that the candidate is required to have experience with Python and Java applications, AWS applications, CI/CD pipelines and tools, machine learning frameworks, and data pipelines. However, I don't see any mention of experience with languages like C++ and Scala. Would it be beneficial to include proficiency in these languages as part of the job requirements?\\nHuman: yes candidates needs to have an experience with scala\\nAI: Great, thank you for confirming that. In addition to Scala, the standard skill set also suggests proficiency in Pyspark. Would you like to include this in your job requirements as well?\\nHuman: No it us not needed\\nAI: Understood. The standard skill set also indicates a need for knowledge in system design and architecture. Does the role require this expertise as well?\"}"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JDAIB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
