{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_title = \"data engineer\"\n",
    "job_description = \"\"\"Our Purpose\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Title And Summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Senior Data Engineer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Job Title\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Senior Data Engineer- Data & Services\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As a Senior Data Engineer, you will be developing new services and data pipelines for the success of the commercial technology integration of Dynamic Yield with Mastercard Data & Services and other Mastercard products!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dynamic Yield is the newest addition to Mastercard’s existing suite of services. It is a state-of-the-art software-as-a-service (SaaS) personalization platform and decision engine company that helps businesses deliver digital customer experiences that are personalized, optimized, and synchronized across any touchpoints.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You will play a significant role in designing, developing, and commercializing new services focused on product synergies across MA data and Services and the Dynamic yield products. These synergies will help businesses of all sizes deliver individualized product recommendations, offers, and content based on a range of factors, including past purchases, page views, time of day, current store traffic, and trending products – all in real time to their customers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As an international business, the software capabilities you design for Mastercard will operate at a massive scale requiring a focus on performance, security, and reliability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Role\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As Single-threaded owner monitor objectives for your teams to align with sprint goals and priorities.\n",
    "Develop an overall strategic technical plan and create architecture proposals based on identified solution gaps. As a recognized subject matter expert, lead planning, design, and implementation of technical solutions\n",
    "Be a significant, hands-on contributor to the team to plan, design, and develop data pipelines using Python.\n",
    "Design, implement, and continuously expand data pipelines by performing extraction, transformation, and loading activities\n",
    "Deliver code with exceptional quality and security that operates at scale.\n",
    "Perform code reviews, and retrospectives, and manage the acceptance of Pull Requests using Git.\n",
    "Collaborate with TPMs, PM-Ts, and product owners to bring to life amazing new service capabilities.\n",
    "Coach your team in engineering best practices, including 12-factor app design.\n",
    "Coach your team on Agile practices, including Daily Scrums, retrospectives, planning, and grooming sessions, to operate and thrive as a high-performing team.\n",
    "Ensure that systems your team creates comply with Mastercard engineering best practices and governance models, including security, operations, and Enterprise Architecture requirements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "All About You\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You have experience leading the development of data pipelines using Python.\n",
    "You have experience using Big Data storage technologies such as Hadoop, Hive, Apache Spark, and Apache Nifi and delivering solutions that leverage them on a global scale.\n",
    "You have strong knowledge and understanding of data-warehousing and data-modeling techniques\n",
    "You have experience developing and maintaining data pipelines using ETL processes.\n",
    "You have experience using storage technologies such as PostgreSQL and delivering solutions that leverage them on a global scale\n",
    "You are passionate about the art of delivering the highest quality software to customers and doing the right thing.\n",
    "You have excellent communication skills with both technical and non-technical people.\n",
    "You have the ability to be self-started, quickly learn and implement new technologies, frameworks, and tools and support multiple concurrent activities, and interface with external/internal resources, working as a member of a matrix-based diverse and geographically distributed project team.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Corporate Security Responsibility\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Abide by Mastercard’s security policies and practices;\n",
    "Ensure the confidentiality and integrity of the information being accessed;\n",
    "Report any suspected information security violation or breach, and\n",
    "Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pay Ranges\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Arlington, Virginia: $129,000 - $199,000 USD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answered Questions:\n",
      "    1. Role Definition: The role is for a Senior Data Engineer in the Data & Services department. The candidate will be responsible for developing new services and data pipelines, focusing on the commercial technology integration of Dynamic Yield with Mastercard Data & Services and other Mastercard products. They will play a significant role in designing, developing, and commercializing new services focused on product synergies across MA data and Services and the Dynamic yield products.\n",
      "    2. Key Responsibilities: The key responsibilities include developing an overall strategic technical plan and creating architecture proposals based on identified solution gaps, planning, designing, and developing data pipelines using Python, implementing data pipelines by performing extraction, transformation, loading activities, performing code reviews and managing the acceptance of Pull Requests using Git.\n",
      "    3. Experience(make a list if more than 1): The candidate should have experience leading the development of data pipelines using Python, using Big Data storage technologies such as Hadoop, Hive, Apache Spark, Apache Nifi on a global scale. They should also have strong knowledge and understanding of data-warehousing and data-modeling techniques as well as experience developing and maintaining data pipelines using ETL processes.\n",
      "    4. Education and Certifications: Not Provided\n",
      "    5. What are the must have or essential skills for this role?(max 4): Experience leading development of data pipelines using Python; Experience with Big Data storage technologies like Hadoop, Hive; Understanding of data-warehousing/data-modeling techniques; Experience with ETL processes.\n",
      "    6. What are the good-to-have skills for this role?(max 2): Experience with PostgreSQL; Excellent communication skills with both technical/non-technical people.\n",
      "    7. Growth Opportunities: Not Provided\n",
      "    8. Tools and Software: Familiarity with Python; Big Data storage technologies such as Hadoop,Hive,Apace Spark,Apace Nifi; PostgreSQL; Git\n",
      "    9. Budget and Compensation: The budget for this position is between $129,000 - $199,000 USD.\n",
      "    10. Technical Job Functions: The technical job functions include developing data pipelines using Python, using Big Data storage technologies such as Hadoop, Hive, Apache Spark, and Apache Nifi on a global scale.\n",
      "    11. Project and Task Management: This role includes project management as the candidate will need to monitor objectives for their teams to align with sprint goals and priorities.\n",
      "    12. Seniority Level(Suggest on the basis of description if not provided explicitly): Senior-level, hands-on\n",
      "    13. Work Environment: Not Provided\n",
      "    14. Acceptable Work Location/s: Arlington, Virginia\n",
      "    15. Which specific industry the role belongs to?: Financial Services/Technology\n",
      "\n",
      "Unanswered Questions:\n",
      "   4. Education and Certifications: Not Provided\n",
      "   7. Growth Opportunities: Not Provided\n",
      "   13. Work Environment: Not Provided\n",
      "\n",
      "Open-ended Questions:\n",
      "   1. What specific tools or frameworks does the candidate need to be familiar with in order to develop data pipelines using Python?\n",
      "   2. Can you provide more detail about the \"Big Data storage technologies\" mentioned in the job description? Are there any specific tools or platforms that are preferred?\n",
      "   3. How critical is it for candidates to have prior experience working in financial services or technology industries?\n"
     ]
    }
   ],
   "source": [
    "Questions = f\"\"\"1. Role Definition: Can you please provide a brief overview of the role we're looking to fill?Make a summary of the overall job description for that.\n",
    "2. Key Responsibilities: What are the top 3-5 key responsibilities for this role?\n",
    "3. Experience(make a list if more than 1): What specific skills and experiences are very essential for this role?\n",
    "4. Education and Certifications: What educational qualifications or certifications are required or desirable for this role?\n",
    "5. What are the must have or essential skills for this role?(max 4)- Make sure to include only crucial or necessary skills from the job description\n",
    "6. What are the good-to-have skills for this role?(max 2)-This can include preferred skills, experience or expertise\n",
    "7. Growth Opportunities: What growth opportunities are available for this role within the organization?\n",
    "8. Tools and Software: Are there any specific tools, software, or equipment that the candidate should be familiar with?\n",
    "9. Budget and Compensation: What is the budget for this position? What is the proposed salary range?\n",
    "10. Technical Job Functions: What are the technical job functions related to this role?\n",
    "11. Project and Task Management: Does this role include project management and require the use of different project management methodologies such as scrum, sprint, kanban?\n",
    "12. Seniority Level(Suggest on the basis of description if not provided explicitlely): What is the seniority level of this role?\n",
    "Entry-level/Mid-level, hands-on/Senior-level, hands-on/Manager, hands-on/Manager, with direct reports\n",
    "13. Work Environment: What is the work environment?\n",
    "Remote/Hybrid(partly remote)/In-office\n",
    "14. Acceptable Work Location/s: What are the acceptable work locations?\n",
    "Any location (Global), Within the USA,LATAM (Latin America),EU (European Union),APAC (Asia-Pacific),Specific countries (please specify below), City, State OR Metropolitan area\n",
    "15. Which specific industry the role belongs to?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You are a job description reviewer who reviews and answers each point in detail.\n",
    "    You are responsible of reviewing a given job description along with questions, \n",
    "    You need to capture/extract the answers from the job description and map them to the relevant question.\n",
    "    (Dont use colons in the list)\n",
    "    \n",
    "    =======================================\n",
    "    Questions:\n",
    "        '''{Questions}'''\n",
    "\n",
    "    Role Title:\n",
    "        '''{role_title}'''\n",
    "\n",
    "    Human:\n",
    "        '''{job_description}'''\n",
    "    ======================================\n",
    "    Answered Questions:\n",
    "    <<Question number. Question title: Answer>>\n",
    "    ======================================\n",
    "    Unanswered Questions: (This must include the questions whose information is not provided in the job description)\n",
    "    <<Question number. Question title:Not Provided>>\n",
    "    ======================================\n",
    "    Open-ended Questions:(3 questions from hiring manager, its most IMPORTANT part. Use your knowledge and ask specifically ask about any technical skills, knowledge, framework etc. needed to succeed as a {role_title}). It can include the questions about related skils and you have to think critically for that.\n",
    "    <<<<Question number. Question title: Question >>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5, model=\"gpt-4\", max_tokens=1300, model_kwargs={\"frequency_penalty\": 0.5})\n",
    "\n",
    "key_info = llm.predict(prompt)\n",
    "print(key_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unansques(response):\n",
    "    lines = response.split('\\n')\n",
    "\n",
    "# Initialize variables to store the extracted parts\n",
    "    unanswered_questions = []\n",
    "    open_ended_questions = []\n",
    "    total_question = []\n",
    "    # Flag to identify the section being processed\n",
    "    current_section = None\n",
    "\n",
    "    # Loop through the lines and extract the relevant sections\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Unanswered Questions:\"):\n",
    "            current_section = \"Unanswered Questions\"\n",
    "        elif line.startswith(\"Open-ended Questions:\"):\n",
    "            current_section = \"Open-ended Questions\"\n",
    "        elif current_section:\n",
    "            # Append the lines to the appropriate section\n",
    "            if line.strip():\n",
    "                if current_section == \"Unanswered Questions\":\n",
    "                    unanswered_questions.append(line.strip())\n",
    "                elif current_section == \"Open-ended Questions\":\n",
    "                    open_ended_questions.append(line.strip())\n",
    "\n",
    "    comb = unanswered_questions + open_ended_questions\n",
    "\n",
    "    for question in comb:\n",
    "        total_question.append(question.split('.')[1])\n",
    "    return total_question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Education and Certifications: Not Provided',\n",
       " ' Growth Opportunities: Not Provided',\n",
       " ' Work Environment: Not Provided',\n",
       " ' What specific tools or frameworks does the candidate need to be familiar with in order to develop data pipelines using Python?',\n",
       " ' Can you provide more detail about the \"Big Data storage technologies\" mentioned in the job description? Are there any specific tools or platforms that are preferred?',\n",
       " ' How critical is it for candidates to have prior experience working in financial services or technology industries?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unansques(key_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Answer:  The role of a Data Engineer involves designing, building, and maintaining data pipelines and infrastructure that support the collection, storage, and processing of various types of data from autonomous vehicles and related systems. The role also includes working with large-scale datasets, ensuring data quality, implementing data governance practices, and collaborating with cross-functional teams to develop data models, optimize data workflows, and contribute to the overall improvement of data architecture and systems.', 'Question: Key Responsibilities', 'Answer:  The top responsibilities for this role are maintaining data and integration pipelines, ensuring data quality, implementing data governance practices, collaborating with cross-functional teams to develop data models and optimize data workflows, and contributing to the overall improvement of data architecture and systems.', 'Question: Experience', 'Answer:  The essential experiences for this role are 12+ years of development in Python or Go, 2+ years of experience in Google Cloud native architectures, experience with traditional Analytic Warehouse solutions, Big Data technologies, Real Time Streaming, performance, and scalability, SQL knowledge (query performance tuning, index maintenance, etc.) as well as an understanding of database structure, knowledge of data modelling principles, and knowledge of at least one ETL tool (SSIS, Informatica, Talend, etc.).', 'Question: Education and Certifications', \"Answer:  The required educational qualifications for this role are a Bachelor's degree or equivalent practical experience. A Master's degree or PhD in a technical field (e.g., Computer Science, Engineering, and Mathematics) is preferred. GCP Certified Data Engineer/Professional Architect is also preferred.\", 'Question: Must have skills', 'Answer:  The must-have skills for this role are Python or Go, Google Cloud native architectures, SQL, data modelling principles, and knowledge of at least one ETL tool.', 'Question: Good-to-have skills', \"Answer:  The good-to-have skills for this role are a Master's degree or PhD in a technical field and GCP Certified Data Engineer/Professional Architect.\", 'Question: Growth Opportunities', 'Answer:  Not Provided', 'Question: Tools and Software', 'Answer:  The candidate should be familiar with Python or Go, Google Cloud native architectures, SQL, data modelling principles, and at least one ETL tool (SSIS, Informatica, Talend, etc.).', 'Question: Budget and Compensation', 'Question: Technical Job Functions', 'Answer:  The technical job functions related to this role include maintaining data and integration pipelines, ensuring data quality, implementing data governance practices, collaborating with cross-functional teams to develop data models and optimize data workflows, and contributing to the overall improvement of data architecture and systems.', 'Question: Project and Task Management', 'Question: Seniority Level', 'Answer:  Given the requirement of 12+ years of development experience, this role can be considered a Senior-level, hands-on role.', 'Question: Work Environment', 'Question: Acceptable Work Location/s', 'Answer:  The acceptable work location for this role is Mountain View, CA.']\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key_info= \"\"\"Question: Role Definition\n",
    "Answer:  The role of a Data Engineer involves designing, building, and maintaining data pipelines and infrastructure that support the collection, storage, and processing of various types of data from autonomous vehicles and related systems. The role also includes working with large-scale datasets, ensuring data quality, implementing data governance practices, and collaborating with cross-functional teams to develop data models, optimize data workflows, and contribute to the overall improvement of data architecture and systems.\n",
    "\n",
    "Question: Key Responsibilities\n",
    "Answer:  The top responsibilities for this role are maintaining data and integration pipelines, ensuring data quality, implementing data governance practices, collaborating with cross-functional teams to develop data models and optimize data workflows, and contributing to the overall improvement of data architecture and systems.\n",
    "\n",
    "Question: Experience\n",
    "Answer:  The essential experiences for this role are 12+ years of development in Python or Go, 2+ years of experience in Google Cloud native architectures, experience with traditional Analytic Warehouse solutions, Big Data technologies, Real Time Streaming, performance, and scalability, SQL knowledge (query performance tuning, index maintenance, etc.) as well as an understanding of database structure, knowledge of data modelling principles, and knowledge of at least one ETL tool (SSIS, Informatica, Talend, etc.).\n",
    "\n",
    "Question: Education and Certifications\n",
    "Answer:  The required educational qualifications for this role are a Bachelor's degree or equivalent practical experience. A Master's degree or PhD in a technical field (e.g., Computer Science, Engineering, and Mathematics) is preferred. GCP Certified Data Engineer/Professional Architect is also preferred.\n",
    "\n",
    "Question: Must have skills\n",
    "Answer:  The must-have skills for this role are Python or Go, Google Cloud native architectures, SQL, data modelling principles, and knowledge of at least one ETL tool.\n",
    "\n",
    "Question: Good-to-have skills\n",
    "Answer:  The good-to-have skills for this role are a Master's degree or PhD in a technical field and GCP Certified Data Engineer/Professional Architect.\n",
    "\n",
    "Question: Growth Opportunities\n",
    "Answer:  Not Provided\n",
    "\n",
    "Question: Tools and Software\n",
    "Answer:  The candidate should be familiar with Python or Go, Google Cloud native architectures, SQL, data modelling principles, and at least one ETL tool (SSIS, Informatica, Talend, etc.).\n",
    "\n",
    "Question: Budget and Compensation\n",
    "Answer:  Not Provided\n",
    "\n",
    "Question: Technical Job Functions\n",
    "Answer:  The technical job functions related to this role include maintaining data and integration pipelines, ensuring data quality, implementing data governance practices, collaborating with cross-functional teams to develop data models and optimize data workflows, and contributing to the overall improvement of data architecture and systems.\n",
    "\n",
    "Question: Project and Task Management\n",
    "Answer:  Not Provided\n",
    "\n",
    "Question: Seniority Level\n",
    "Answer:  Given the requirement of 12+ years of development experience, this role can be considered a Senior-level, hands-on role.\n",
    "\n",
    "Question: Work Environment\n",
    "Answer:  Not Provided\n",
    "\n",
    "Question: Acceptable Work Location/s\n",
    "Answer:  The acceptable work location for this role is Mountain View, CA.\"\"\"\n",
    "\n",
    "\n",
    "role_description = key_info\n",
    "\n",
    "\n",
    "list_questions = []\n",
    "for question in range(len(st.session_state.questions)):\n",
    "            \n",
    "                    \n",
    "            answer = st.text_input(f'Question: {st.session_state.questions[question]}', key = f\"{question}+++\")\n",
    "                            \n",
    "            if answer:\n",
    "                list_questions.append(answer)\n",
    "                conversation.empty()\n",
    "                exists = any(message['message'] == answer for message in st.session_state.messages)\n",
    "                if not exists:\n",
    "                    st.session_state.messages.append({\"sender\": \"user\", \"message\": f\"{st.session_state.questions[question]}: {answer}\"})\n",
    "                conversation.write(display_messages(st.session_state.messages))\n",
    "                with st.chat_message(\"user\"):\n",
    "                    st.write(answer)\n",
    "                with open('CONTEXT.txt', \"a\") as f:\n",
    "                    f.write(\"\\nQuestion:\" + st.session_state.questions[question.split('.')[1]] + \"\\n\" + \"Answer:\" + answer + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JDAIB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
